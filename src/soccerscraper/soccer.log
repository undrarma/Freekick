2020-05-27 16:51:34 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: soccerscraper)
2020-05-27 16:51:34 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-27 16:51:34 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-27 16:51:34 [scrapy.extensions.telnet] INFO: Telnet Password: e6ad09cbcc405975
2020-05-27 16:51:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-27 16:51:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-27 16:51:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-27 16:51:35 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-27 16:51:35 [scrapy.core.engine] INFO: Spider opened
2020-05-27 16:51:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-27 16:51:35 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-27 16:51:35 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-27 16:51:35 [scrapy.extensions.telnet] INFO: Telnet Password: 6953c81ed0f5a7df
2020-05-27 16:51:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-27 16:51:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-27 16:51:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-27 16:51:35 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-27 16:51:35 [scrapy.core.engine] INFO: Spider opened
2020-05-27 16:51:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-27 16:51:35 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2020-05-27 16:51:47 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-27 16:51:47 [scrapy.extensions.feedexport] INFO: Stored json feed (1 items) in: soccer.json
2020-05-27 16:51:47 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1791,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 38702,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'elapsed_time_seconds': 11.701041,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 27, 13, 51, 47, 143491),
 'item_scraped_count': 1,
 'log_count/INFO': 20,
 'request_depth_max': 2,
 'response_received_count': 4,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2020, 5, 27, 13, 51, 35, 442450)}
2020-05-27 16:51:47 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-27 16:51:47 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-27 16:51:47 [scrapy.extensions.feedexport] INFO: Stored json feed (1 items) in: soccer.json
2020-05-27 16:51:47 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1791,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 39193,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'elapsed_time_seconds': 11.789019,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 27, 13, 51, 47, 243484),
 'item_scraped_count': 1,
 'log_count/INFO': 15,
 'request_depth_max': 2,
 'response_received_count': 4,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2020, 5, 27, 13, 51, 35, 454465)}
2020-05-27 16:51:47 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-27 16:54:22 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: soccerscraper)
2020-05-27 16:54:22 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-27 16:54:22 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-27 16:54:22 [scrapy.extensions.telnet] INFO: Telnet Password: 6e95a70c5453c78e
2020-05-27 16:54:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-27 16:54:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-27 16:54:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-27 16:54:22 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-27 16:54:22 [scrapy.core.engine] INFO: Spider opened
2020-05-27 16:54:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-27 16:54:22 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-27 16:54:22 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-27 16:54:22 [scrapy.extensions.telnet] INFO: Telnet Password: 2ad9561a62fd0429
2020-05-27 16:54:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-27 16:54:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-27 16:54:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-27 16:54:22 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-27 16:54:22 [scrapy.core.engine] INFO: Spider opened
2020-05-27 16:54:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-27 16:54:22 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2020-05-27 16:54:26 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-27 16:54:26 [scrapy.extensions.feedexport] INFO: Stored json feed (1 items) in: soccer.json
2020-05-27 16:54:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1791,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 38760,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'elapsed_time_seconds': 3.599098,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 27, 13, 54, 26, 199352),
 'item_scraped_count': 1,
 'log_count/INFO': 20,
 'request_depth_max': 2,
 'response_received_count': 4,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2020, 5, 27, 13, 54, 22, 600254)}
2020-05-27 16:54:26 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-27 16:54:30 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-27 16:54:30 [scrapy.extensions.feedexport] INFO: Stored json feed (1 items) in: soccer.json
2020-05-27 16:54:30 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1791,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 39246,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'elapsed_time_seconds': 7.55812,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 27, 13, 54, 30, 174370),
 'item_scraped_count': 1,
 'log_count/INFO': 15,
 'request_depth_max': 2,
 'response_received_count': 4,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2020, 5, 27, 13, 54, 22, 616250)}
2020-05-27 16:54:30 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-27 16:58:27 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: soccerscraper)
2020-05-27 16:58:27 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-27 16:58:27 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-27 16:58:27 [scrapy.extensions.telnet] INFO: Telnet Password: bc6a408e5e2755a7
2020-05-27 16:58:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-27 16:58:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-27 16:58:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-27 16:58:27 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-27 16:58:27 [scrapy.core.engine] INFO: Spider opened
2020-05-27 16:58:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-27 16:58:27 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-27 16:58:27 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-27 16:58:27 [scrapy.extensions.telnet] INFO: Telnet Password: 9420327327c17869
2020-05-27 16:58:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-27 16:58:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-27 16:58:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-27 16:58:27 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-27 16:58:27 [scrapy.core.engine] INFO: Spider opened
2020-05-27 16:58:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-27 16:58:27 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2020-05-27 16:58:39 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x000001D6DAFCCEC8>>
Traceback (most recent call last):
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\defer.py", line 161, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\extensions\feedexport.py", line 260, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\exporters.py", line 129, in export_item
    data = self.encoder.encode(itemdict)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\serialize.py", line 36, in default
    return super(ScrapyJSONEncoder, self).default(o)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type bytes is not JSON serializable
2020-05-27 16:58:39 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-27 16:58:39 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1791,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 38656,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'elapsed_time_seconds': 11.538249,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 27, 13, 58, 39, 513494),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 19,
 'request_depth_max': 2,
 'response_received_count': 4,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2020, 5, 27, 13, 58, 27, 975245)}
2020-05-27 16:58:39 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-27 16:58:43 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x000001D6DB2BE1C8>>
Traceback (most recent call last):
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\defer.py", line 161, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\extensions\feedexport.py", line 260, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\exporters.py", line 129, in export_item
    data = self.encoder.encode(itemdict)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\serialize.py", line 36, in default
    return super(ScrapyJSONEncoder, self).default(o)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type bytes is not JSON serializable
2020-05-27 16:58:43 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-27 16:58:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1791,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 39152,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'elapsed_time_seconds': 15.5652,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 27, 13, 58, 43, 560440),
 'item_scraped_count': 1,
 'log_count/ERROR': 2,
 'log_count/INFO': 13,
 'request_depth_max': 2,
 'response_received_count': 4,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2020, 5, 27, 13, 58, 27, 995240)}
2020-05-27 16:58:43 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-27 16:58:58 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: soccerscraper)
2020-05-27 16:58:58 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-27 16:58:58 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-27 16:58:58 [scrapy.extensions.telnet] INFO: Telnet Password: 52fa10ffd571ca61
2020-05-27 16:58:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-27 16:58:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-27 16:58:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-27 16:58:59 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-27 16:58:59 [scrapy.core.engine] INFO: Spider opened
2020-05-27 16:58:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-27 16:58:59 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-27 16:58:59 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-27 16:58:59 [scrapy.extensions.telnet] INFO: Telnet Password: 76ae73e766e42303
2020-05-27 16:58:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-27 16:58:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-27 16:58:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-27 16:58:59 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-27 16:58:59 [scrapy.core.engine] INFO: Spider opened
2020-05-27 16:58:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-27 16:58:59 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2020-05-27 16:59:06 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x000002A389F801C8>>
Traceback (most recent call last):
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\defer.py", line 161, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\extensions\feedexport.py", line 260, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\exporters.py", line 129, in export_item
    data = self.encoder.encode(itemdict)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\serialize.py", line 36, in default
    return super(ScrapyJSONEncoder, self).default(o)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type bytes is not JSON serializable
2020-05-27 16:59:06 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-27 16:59:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1791,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 38730,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'elapsed_time_seconds': 7.510104,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 27, 13, 59, 6, 753904),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 19,
 'request_depth_max': 2,
 'response_received_count': 4,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2020, 5, 27, 13, 58, 59, 243800)}
2020-05-27 16:59:06 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-27 16:59:06 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x000002A389F830C8>>
Traceback (most recent call last):
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\defer.py", line 161, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\extensions\feedexport.py", line 260, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\exporters.py", line 129, in export_item
    data = self.encoder.encode(itemdict)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\serialize.py", line 36, in default
    return super(ScrapyJSONEncoder, self).default(o)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type bytes is not JSON serializable
2020-05-27 16:59:06 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-27 16:59:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1791,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 39202,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'elapsed_time_seconds': 7.630071,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 27, 13, 59, 6, 897865),
 'item_scraped_count': 1,
 'log_count/ERROR': 2,
 'log_count/INFO': 13,
 'request_depth_max': 2,
 'response_received_count': 4,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2020, 5, 27, 13, 58, 59, 267794)}
2020-05-27 16:59:06 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-27 17:00:03 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: soccerscraper)
2020-05-27 17:00:03 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-27 17:00:03 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-27 17:00:03 [scrapy.extensions.telnet] INFO: Telnet Password: 5a1f86cbf1a516f3
2020-05-27 17:00:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-27 17:00:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-27 17:00:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-27 17:00:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-27 17:00:04 [scrapy.core.engine] INFO: Spider opened
2020-05-27 17:00:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-27 17:00:04 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-27 17:00:04 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-27 17:00:04 [scrapy.extensions.telnet] INFO: Telnet Password: d88b4ff6c95ca33d
2020-05-27 17:00:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-27 17:00:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-27 17:00:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-27 17:00:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-27 17:00:04 [scrapy.core.engine] INFO: Spider opened
2020-05-27 17:00:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-27 17:00:04 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2020-05-27 17:00:19 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x000001D69E874EC8>>
Traceback (most recent call last):
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\defer.py", line 161, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\extensions\feedexport.py", line 260, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\exporters.py", line 129, in export_item
    data = self.encoder.encode(itemdict)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\serialize.py", line 36, in default
    return super(ScrapyJSONEncoder, self).default(o)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type bytes is not JSON serializable
2020-05-27 17:00:19 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x000001D69E8276C8>>
Traceback (most recent call last):
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\defer.py", line 161, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\extensions\feedexport.py", line 260, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\exporters.py", line 129, in export_item
    data = self.encoder.encode(itemdict)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\serialize.py", line 36, in default
    return super(ScrapyJSONEncoder, self).default(o)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type bytes is not JSON serializable
2020-05-27 17:00:19 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-27 17:00:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1791,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 38676,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'elapsed_time_seconds': 15.684035,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 27, 14, 0, 19, 819808),
 'item_scraped_count': 1,
 'log_count/ERROR': 2,
 'log_count/INFO': 19,
 'request_depth_max': 2,
 'response_received_count': 4,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2020, 5, 27, 14, 0, 4, 135773)}
2020-05-27 17:00:19 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-27 17:00:19 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-27 17:00:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1791,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 39212,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'elapsed_time_seconds': 15.66404,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 27, 14, 0, 19, 823806),
 'item_scraped_count': 1,
 'log_count/ERROR': 2,
 'log_count/INFO': 13,
 'request_depth_max': 2,
 'response_received_count': 4,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2020, 5, 27, 14, 0, 4, 159766)}
2020-05-27 17:00:19 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-27 17:01:02 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: soccerscraper)
2020-05-27 17:01:02 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-27 17:01:02 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-27 17:01:02 [scrapy.extensions.telnet] INFO: Telnet Password: bf8d65abb6267083
2020-05-27 17:01:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-27 17:01:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-27 17:01:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-27 17:01:03 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-27 17:01:03 [scrapy.core.engine] INFO: Spider opened
2020-05-27 17:01:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-27 17:01:03 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-27 17:01:03 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-27 17:01:03 [scrapy.extensions.telnet] INFO: Telnet Password: 55eb322478a3a86d
2020-05-27 17:01:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-27 17:01:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-27 17:01:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-27 17:01:03 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-27 17:01:03 [scrapy.core.engine] INFO: Spider opened
2020-05-27 17:01:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-27 17:01:03 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2020-05-27 17:01:14 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-27 17:01:14 [scrapy.extensions.feedexport] INFO: Stored json feed (1 items) in: soccer.json
2020-05-27 17:01:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1791,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 38770,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'elapsed_time_seconds': 11.765022,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 27, 14, 1, 14, 996798),
 'item_scraped_count': 1,
 'log_count/INFO': 20,
 'request_depth_max': 2,
 'response_received_count': 4,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2020, 5, 27, 14, 1, 3, 231776)}
2020-05-27 17:01:15 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-27 17:01:19 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-27 17:01:19 [scrapy.extensions.feedexport] INFO: Stored json feed (1 items) in: soccer.json
2020-05-27 17:01:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1791,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 39130,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'elapsed_time_seconds': 15.907996,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 27, 14, 1, 19, 159766),
 'item_scraped_count': 1,
 'log_count/INFO': 15,
 'request_depth_max': 2,
 'response_received_count': 4,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2020, 5, 27, 14, 1, 3, 251770)}
2020-05-27 17:01:19 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-27 17:01:56 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: soccerscraper)
2020-05-27 17:01:56 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-27 17:01:56 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-27 17:01:56 [scrapy.extensions.telnet] INFO: Telnet Password: c0511d335918d969
2020-05-27 17:01:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-27 17:01:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-27 17:01:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-27 17:01:56 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-27 17:01:56 [scrapy.core.engine] INFO: Spider opened
2020-05-27 17:01:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-27 17:01:56 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-27 17:01:56 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-27 17:01:56 [scrapy.extensions.telnet] INFO: Telnet Password: 539adc510fe890bd
2020-05-27 17:01:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-27 17:01:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-27 17:01:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-27 17:01:56 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-27 17:01:56 [scrapy.core.engine] INFO: Spider opened
2020-05-27 17:01:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-27 17:01:56 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2020-05-27 17:02:00 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-27 17:02:00 [scrapy.extensions.feedexport] INFO: Stored json feed (1 items) in: soccer.json
2020-05-27 17:02:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1791,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 38747,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'elapsed_time_seconds': 3.616218,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 27, 14, 2, 0, 473379),
 'item_scraped_count': 1,
 'log_count/INFO': 20,
 'request_depth_max': 2,
 'response_received_count': 4,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2020, 5, 27, 14, 1, 56, 857161)}
2020-05-27 17:02:00 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-27 17:02:08 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-27 17:02:08 [scrapy.extensions.feedexport] INFO: Stored json feed (1 items) in: soccer.json
2020-05-27 17:02:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1791,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 39168,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'elapsed_time_seconds': 11.826142,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 27, 14, 2, 8, 695300),
 'item_scraped_count': 1,
 'log_count/INFO': 15,
 'request_depth_max': 2,
 'response_received_count': 4,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2020, 5, 27, 14, 1, 56, 869158)}
2020-05-27 17:02:08 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-27 17:10:18 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: soccerscraper)
2020-05-27 17:10:18 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-27 17:10:19 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-27 17:10:19 [scrapy.extensions.telnet] INFO: Telnet Password: ab203102f155b871
2020-05-27 17:10:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-27 17:10:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-27 17:10:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-27 17:10:19 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-27 17:10:19 [scrapy.core.engine] INFO: Spider opened
2020-05-27 17:10:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-27 17:10:19 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-27 17:10:19 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-27 17:10:19 [scrapy.extensions.telnet] INFO: Telnet Password: 5c58f7c03ff4c3d6
2020-05-27 17:10:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-27 17:10:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-27 17:10:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-27 17:10:19 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-27 17:10:19 [scrapy.core.engine] INFO: Spider opened
2020-05-27 17:10:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-27 17:10:19 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2020-05-27 17:10:31 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-27 17:10:31 [scrapy.extensions.feedexport] INFO: Stored json feed (1 items) in: soccer.json
2020-05-27 17:10:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1791,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 38644,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'elapsed_time_seconds': 11.91596,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 27, 14, 10, 31, 532016),
 'item_scraped_count': 1,
 'log_count/INFO': 20,
 'request_depth_max': 2,
 'response_received_count': 4,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2020, 5, 27, 14, 10, 19, 616056)}
2020-05-27 17:10:31 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-27 17:10:31 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-27 17:10:31 [scrapy.extensions.feedexport] INFO: Stored json feed (1 items) in: soccer.json
2020-05-27 17:10:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1791,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 39145,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'elapsed_time_seconds': 11.999944,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 27, 14, 10, 31, 627997),
 'item_scraped_count': 1,
 'log_count/INFO': 15,
 'request_depth_max': 2,
 'response_received_count': 4,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2020, 5, 27, 14, 10, 19, 628053)}
2020-05-27 17:10:31 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-27 17:11:31 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: soccerscraper)
2020-05-27 17:11:31 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-27 17:11:31 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-27 17:11:31 [scrapy.extensions.telnet] INFO: Telnet Password: ed813cee66c1db78
2020-05-27 17:11:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-27 17:11:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-27 17:11:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-27 17:11:31 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-27 17:11:31 [scrapy.core.engine] INFO: Spider opened
2020-05-27 17:11:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-27 17:11:31 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-27 17:11:31 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-27 17:11:31 [scrapy.extensions.telnet] INFO: Telnet Password: 2d2f696ec4ba9c2c
2020-05-27 17:11:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-27 17:11:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-27 17:11:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-27 17:11:31 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-27 17:11:31 [scrapy.core.engine] INFO: Spider opened
2020-05-27 17:11:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-27 17:11:31 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2020-05-27 17:11:39 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-27 17:11:39 [scrapy.extensions.feedexport] INFO: Stored json feed (1 items) in: soccer.json
2020-05-27 17:11:39 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1791,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 38573,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'elapsed_time_seconds': 7.410125,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 27, 14, 11, 39, 326748),
 'item_scraped_count': 1,
 'log_count/INFO': 20,
 'request_depth_max': 2,
 'response_received_count': 4,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2020, 5, 27, 14, 11, 31, 916623)}
2020-05-27 17:11:39 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-27 17:11:47 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-27 17:11:47 [scrapy.extensions.feedexport] INFO: Stored json feed (1 items) in: soccer.json
2020-05-27 17:11:47 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1791,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 39179,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'elapsed_time_seconds': 15.464091,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 27, 14, 11, 47, 392710),
 'item_scraped_count': 1,
 'log_count/INFO': 15,
 'request_depth_max': 2,
 'response_received_count': 4,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2020, 5, 27, 14, 11, 31, 928619)}
2020-05-27 17:11:47 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-27 17:12:12 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: soccerscraper)
2020-05-27 17:12:12 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-27 17:12:12 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-27 17:12:12 [scrapy.extensions.telnet] INFO: Telnet Password: 95c89ea011ab4bfa
2020-05-27 17:12:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-27 17:12:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-27 17:12:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-27 17:12:13 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-27 17:12:13 [scrapy.core.engine] INFO: Spider opened
2020-05-27 17:12:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-27 17:12:13 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-27 17:12:13 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-27 17:12:13 [scrapy.extensions.telnet] INFO: Telnet Password: f7f3bba117045ee9
2020-05-27 17:12:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-27 17:12:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-27 17:12:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-27 17:12:13 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-27 17:12:13 [scrapy.core.engine] INFO: Spider opened
2020-05-27 17:12:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-27 17:12:13 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2020-05-27 17:12:20 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-27 17:12:20 [scrapy.extensions.feedexport] INFO: Stored json feed (1 items) in: soccer.json
2020-05-27 17:12:20 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1791,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 39187,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'elapsed_time_seconds': 7.334525,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 27, 14, 12, 20, 717742),
 'item_scraped_count': 1,
 'log_count/INFO': 11,
 'request_depth_max': 2,
 'response_received_count': 4,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2020, 5, 27, 14, 12, 13, 383217)}
2020-05-27 17:12:20 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-27 17:12:24 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-27 17:12:24 [scrapy.extensions.feedexport] INFO: Stored json feed (1 items) in: soccer.json
2020-05-27 17:12:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1791,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 38770,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'elapsed_time_seconds': 11.386622,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 27, 14, 12, 24, 753846),
 'item_scraped_count': 1,
 'log_count/INFO': 24,
 'request_depth_max': 2,
 'response_received_count': 4,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2020, 5, 27, 14, 12, 13, 367224)}
2020-05-27 17:12:24 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-27 17:13:42 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: soccerscraper)
2020-05-27 17:13:42 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-27 17:13:42 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-27 17:13:42 [scrapy.extensions.telnet] INFO: Telnet Password: 7aa2a21e582914b7
2020-05-27 17:13:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-27 17:13:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-27 17:13:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-27 17:13:43 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-27 17:13:43 [scrapy.core.engine] INFO: Spider opened
2020-05-27 17:13:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-27 17:13:43 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-27 17:13:43 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-27 17:13:43 [scrapy.extensions.telnet] INFO: Telnet Password: 099043406909a81d
2020-05-27 17:13:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-27 17:13:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-27 17:13:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-27 17:13:43 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-27 17:13:43 [scrapy.core.engine] INFO: Spider opened
2020-05-27 17:13:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-27 17:13:43 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2020-05-27 17:14:43 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 20 pages/min), scraped 17 items (at 17 items/min)
2020-05-27 17:14:43 [scrapy.extensions.logstats] INFO: Crawled 28 pages (at 28 pages/min), scraped 25 items (at 25 items/min)
2020-05-27 17:14:53 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-27 17:14:53 [scrapy.extensions.feedexport] INFO: Stored json feed (30 items) in: soccer.json
2020-05-27 17:14:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 17886,
 'downloader/request_count': 33,
 'downloader/request_method_count/GET': 33,
 'downloader/response_bytes': 437967,
 'downloader/response_count': 33,
 'downloader/response_status_count/200': 33,
 'elapsed_time_seconds': 69.736321,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 27, 14, 14, 53, 142175),
 'item_scraped_count': 30,
 'log_count/INFO': 13,
 'request_depth_max': 2,
 'response_received_count': 33,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 32,
 'scheduler/dequeued/memory': 32,
 'scheduler/enqueued': 32,
 'scheduler/enqueued/memory': 32,
 'start_time': datetime.datetime(2020, 5, 27, 14, 13, 43, 405854)}
2020-05-27 17:14:53 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-27 17:15:00 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-27 17:15:00 [scrapy.extensions.feedexport] INFO: Stored json feed (28 items) in: soccer.json
2020-05-27 17:15:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16780,
 'downloader/request_count': 31,
 'downloader/request_method_count/GET': 31,
 'downloader/response_bytes': 403302,
 'downloader/response_count': 31,
 'downloader/response_status_count/200': 31,
 'elapsed_time_seconds': 76.767537,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 27, 14, 15, 0, 161414),
 'item_scraped_count': 28,
 'log_count/INFO': 26,
 'request_depth_max': 2,
 'response_received_count': 31,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 30,
 'scheduler/dequeued/memory': 30,
 'scheduler/enqueued': 30,
 'scheduler/enqueued/memory': 30,
 'start_time': datetime.datetime(2020, 5, 27, 14, 13, 43, 393877)}
2020-05-27 17:15:00 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-27 18:36:27 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: soccerscraper)
2020-05-27 18:36:27 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-27 18:36:27 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-27 18:36:28 [scrapy.extensions.telnet] INFO: Telnet Password: 51b0d8ba032b122f
2020-05-27 18:36:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-27 18:36:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-27 18:36:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-27 18:36:34 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-27 18:36:34 [scrapy.core.engine] INFO: Spider opened
2020-05-27 18:36:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-27 18:36:34 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-05-27 18:36:34 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-27 18:36:34 [scrapy.extensions.telnet] INFO: Telnet Password: 55185949be8ad123
2020-05-27 18:36:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-27 18:36:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-27 18:36:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-27 18:36:34 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-27 18:36:34 [scrapy.core.engine] INFO: Spider opened
2020-05-27 18:36:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-27 18:36:34 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2020-05-27 18:37:34 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 24 pages/min), scraped 21 items (at 21 items/min)
2020-05-27 18:37:34 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 25 pages/min), scraped 22 items (at 22 items/min)
2020-05-27 18:37:49 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-27 18:37:49 [scrapy.extensions.feedexport] INFO: Stored json feed (30 items) in: soccer.json
2020-05-27 18:37:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 17886,
 'downloader/request_count': 33,
 'downloader/request_method_count/GET': 33,
 'downloader/response_bytes': 437778,
 'downloader/response_count': 33,
 'downloader/response_status_count/200': 33,
 'elapsed_time_seconds': 74.386363,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 27, 15, 37, 49, 166543),
 'item_scraped_count': 30,
 'log_count/INFO': 13,
 'request_depth_max': 2,
 'response_received_count': 33,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 32,
 'scheduler/dequeued/memory': 32,
 'scheduler/enqueued': 32,
 'scheduler/enqueued/memory': 32,
 'start_time': datetime.datetime(2020, 5, 27, 15, 36, 34, 780180)}
2020-05-27 18:37:49 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-27 18:37:57 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-27 18:37:57 [scrapy.extensions.feedexport] INFO: Stored json feed (28 items) in: soccer.json
2020-05-27 18:37:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16780,
 'downloader/request_count': 31,
 'downloader/request_method_count/GET': 31,
 'downloader/response_bytes': 403454,
 'downloader/response_count': 31,
 'downloader/response_status_count/200': 31,
 'elapsed_time_seconds': 82.857608,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 27, 15, 37, 57, 575298),
 'item_scraped_count': 28,
 'log_count/INFO': 26,
 'request_depth_max': 2,
 'response_received_count': 31,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 30,
 'scheduler/dequeued/memory': 30,
 'scheduler/enqueued': 30,
 'scheduler/enqueued/memory': 30,
 'start_time': datetime.datetime(2020, 5, 27, 15, 36, 34, 717690)}
2020-05-27 18:37:57 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-28 20:29:16 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: soccerscraper)
2020-05-28 20:29:16 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-28 20:29:16 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-28 20:29:16 [scrapy.extensions.telnet] INFO: Telnet Password: b916134efbab71a5
2020-05-28 20:29:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-28 20:29:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-28 20:29:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-28 20:29:17 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-28 20:29:17 [scrapy.core.engine] INFO: Spider opened
2020-05-28 20:29:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-28 20:29:17 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2020-05-28 20:29:20 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-28 20:29:20 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1308,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 26509,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'elapsed_time_seconds': 2.735813,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 28, 17, 29, 20, 78364),
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2020, 5, 28, 17, 29, 17, 342551)}
2020-05-28 20:29:20 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-28 20:29:36 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: soccerscraper)
2020-05-28 20:29:36 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-28 20:29:36 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-28 20:29:36 [scrapy.extensions.telnet] INFO: Telnet Password: 70f719fefa66a20c
2020-05-28 20:29:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-28 20:29:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-28 20:29:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-28 20:29:37 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-28 20:29:37 [scrapy.core.engine] INFO: Spider opened
2020-05-28 20:29:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-28 20:29:37 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2020-05-28 20:29:39 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-28 20:29:39 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1308,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 26414,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'elapsed_time_seconds': 2.527835,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 28, 17, 29, 39, 972528),
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2020, 5, 28, 17, 29, 37, 444693)}
2020-05-28 20:29:39 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-28 20:36:03 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: soccerscraper)
2020-05-28 20:36:03 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-28 20:36:03 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer_test.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-28 20:36:03 [scrapy.extensions.telnet] INFO: Telnet Password: f6f6999b03779b5f
2020-05-28 20:36:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-28 20:36:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-28 20:36:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-28 20:36:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-28 20:36:04 [scrapy.core.engine] INFO: Spider opened
2020-05-28 20:36:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-28 20:36:04 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2020-05-28 20:36:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://en.soccerwiki.org/squad.php?clubid=496> (referer: https://en.soccerwiki.org/wiki.php?action=countryProfile&countryId=GRE)
Traceback (most recent call last):
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "C:\Users\Alex\PycharmProjects\freeKick\soccerscraper\soccerscraper\spiders\soccerwiki.py", line 37, in parse_country
    divisions = response.xpath("//*[@class = 'RcontentBox floatright']//*[@class = 'InnerBorder']")[0]
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2020-05-28 20:36:13 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-28 20:36:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1887,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 38710,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'elapsed_time_seconds': 9.552026,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 28, 17, 36, 13, 665843),
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'request_depth_max': 2,
 'response_received_count': 4,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2020, 5, 28, 17, 36, 4, 113817)}
2020-05-28 20:36:13 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-28 20:36:49 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: soccerscraper)
2020-05-28 20:36:49 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-28 20:36:49 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer_test.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-28 20:36:49 [scrapy.extensions.telnet] INFO: Telnet Password: 9f477a9095edc6b4
2020-05-28 20:36:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-28 20:36:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-28 20:36:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-28 20:36:50 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-28 20:36:50 [scrapy.core.engine] INFO: Spider opened
2020-05-28 20:36:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-28 20:36:50 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2020-05-28 20:36:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://en.soccerwiki.org/player.php?pid=5360> (referer: https://en.soccerwiki.org/squad.php?clubid=496)
Traceback (most recent call last):
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "C:\Users\Alex\PycharmProjects\freeKick\soccerscraper\soccerscraper\spiders\soccerwiki.py", line 85, in parse_player
    league = response.get.meta['league']
AttributeError: 'HtmlResponse' object has no attribute 'get'
2020-05-28 20:36:55 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-28 20:36:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2441,
 'downloader/request_count': 5,
 'downloader/request_method_count/GET': 5,
 'downloader/response_bytes': 53109,
 'downloader/response_count': 5,
 'downloader/response_status_count/200': 5,
 'elapsed_time_seconds': 4.623576,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 28, 17, 36, 55, 28040),
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'request_depth_max': 3,
 'response_received_count': 5,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 5, 28, 17, 36, 50, 404464)}
2020-05-28 20:36:55 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-28 20:37:36 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: soccerscraper)
2020-05-28 20:37:36 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-28 20:37:36 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer_test.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-28 20:37:36 [scrapy.extensions.telnet] INFO: Telnet Password: 59eb7e4e32765959
2020-05-28 20:37:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-28 20:37:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-28 20:37:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-28 20:37:37 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-28 20:37:37 [scrapy.core.engine] INFO: Spider opened
2020-05-28 20:37:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-28 20:37:37 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2020-05-28 20:37:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://en.soccerwiki.org/player.php?pid=5360> (referer: https://en.soccerwiki.org/squad.php?clubid=496)
Traceback (most recent call last):
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "C:\Users\Alex\PycharmProjects\freeKick\soccerscraper\soccerscraper\spiders\soccerwiki.py", line 85, in parse_player
    league = response.get.meta['league']
AttributeError: 'HtmlResponse' object has no attribute 'get'
2020-05-28 20:37:46 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-28 20:37:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2441,
 'downloader/request_count': 5,
 'downloader/request_method_count/GET': 5,
 'downloader/response_bytes': 52976,
 'downloader/response_count': 5,
 'downloader/response_status_count/200': 5,
 'elapsed_time_seconds': 8.567221,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 28, 17, 37, 46, 55336),
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'request_depth_max': 3,
 'response_received_count': 5,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 5, 28, 17, 37, 37, 488115)}
2020-05-28 20:37:46 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-28 20:38:15 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: soccerscraper)
2020-05-28 20:38:15 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-28 20:38:15 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer_test.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-28 20:38:15 [scrapy.extensions.telnet] INFO: Telnet Password: 01a72e0f42393060
2020-05-28 20:38:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-28 20:38:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-28 20:38:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-28 20:38:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-28 20:38:16 [scrapy.core.engine] INFO: Spider opened
2020-05-28 20:38:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-28 20:38:16 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2020-05-28 20:38:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://en.soccerwiki.org/player.php?pid=5360> (referer: https://en.soccerwiki.org/squad.php?clubid=496)
Traceback (most recent call last):
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "C:\Users\Alex\PycharmProjects\freeKick\soccerscraper\soccerscraper\spiders\soccerwiki.py", line 85, in parse_player
    league = response.get.meta['league']
AttributeError: 'HtmlResponse' object has no attribute 'get'
2020-05-28 20:38:28 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-28 20:38:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2441,
 'downloader/request_count': 5,
 'downloader/request_method_count/GET': 5,
 'downloader/response_bytes': 53100,
 'downloader/response_count': 5,
 'downloader/response_status_count/200': 5,
 'elapsed_time_seconds': 12.518879,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 28, 17, 38, 28, 883404),
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'request_depth_max': 3,
 'response_received_count': 5,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 5, 28, 17, 38, 16, 364525)}
2020-05-28 20:38:28 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-28 20:39:06 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: soccerscraper)
2020-05-28 20:39:06 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-28 20:39:06 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer_test.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-28 20:39:06 [scrapy.extensions.telnet] INFO: Telnet Password: 80b4c228bedc099a
2020-05-28 20:39:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-28 20:39:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-28 20:39:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-28 20:39:06 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-28 20:39:06 [scrapy.core.engine] INFO: Spider opened
2020-05-28 20:39:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-28 20:39:06 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2020-05-28 20:39:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://en.soccerwiki.org/player.php?pid=5360> (referer: https://en.soccerwiki.org/squad.php?clubid=496)
Traceback (most recent call last):
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "C:\Users\Alex\PycharmProjects\freeKick\soccerscraper\soccerscraper\spiders\soccerwiki.py", line 85, in parse_player
    league = response.meta.get['league']
TypeError: 'builtin_function_or_method' object is not subscriptable
2020-05-28 20:39:15 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-28 20:39:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2441,
 'downloader/request_count': 5,
 'downloader/request_method_count/GET': 5,
 'downloader/response_bytes': 52836,
 'downloader/response_count': 5,
 'downloader/response_status_count/200': 5,
 'elapsed_time_seconds': 9.167156,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 28, 17, 39, 15, 776490),
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'request_depth_max': 3,
 'response_received_count': 5,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2020, 5, 28, 17, 39, 6, 609334)}
2020-05-28 20:39:15 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-28 20:40:10 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: soccerscraper)
2020-05-28 20:40:10 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-28 20:40:10 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer_test.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-28 20:40:10 [scrapy.extensions.telnet] INFO: Telnet Password: ff4cf05597d5c7ef
2020-05-28 20:40:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-28 20:40:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-28 20:40:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-28 20:40:11 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-28 20:40:11 [scrapy.core.engine] INFO: Spider opened
2020-05-28 20:40:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-28 20:40:11 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2020-05-28 20:40:25 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-28 20:40:25 [scrapy.extensions.feedexport] INFO: Stored json feed (1 items) in: soccer_test.json
2020-05-28 20:40:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2441,
 'downloader/request_count': 5,
 'downloader/request_method_count/GET': 5,
 'downloader/response_bytes': 52849,
 'downloader/response_count': 5,
 'downloader/response_status_count/200': 5,
 'elapsed_time_seconds': 13.846747,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 28, 17, 40, 25, 266093),
 'item_scraped_count': 1,
 'log_count/INFO': 11,
 'request_depth_max': 3,
 'response_received_count': 5,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'start_time': datetime.datetime(2020, 5, 28, 17, 40, 11, 419346)}
2020-05-28 20:40:25 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-28 20:41:56 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: soccerscraper)
2020-05-28 20:41:56 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-28 20:41:56 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer_test.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-28 20:41:56 [scrapy.extensions.telnet] INFO: Telnet Password: a538d7b682a9a086
2020-05-28 20:41:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-28 20:41:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-28 20:41:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-28 20:41:57 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-28 20:41:57 [scrapy.core.engine] INFO: Spider opened
2020-05-28 20:41:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-28 20:41:57 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2020-05-28 20:42:06 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020A20942C48>>
Traceback (most recent call last):
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\defer.py", line 161, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\extensions\feedexport.py", line 260, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\exporters.py", line 129, in export_item
    data = self.encoder.encode(itemdict)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\serialize.py", line 36, in default
    return super(ScrapyJSONEncoder, self).default(o)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type Selector is not JSON serializable
2020-05-28 20:42:06 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-28 20:42:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2441,
 'downloader/request_count': 5,
 'downloader/request_method_count/GET': 5,
 'downloader/response_bytes': 53034,
 'downloader/response_count': 5,
 'downloader/response_status_count/200': 5,
 'elapsed_time_seconds': 8.647203,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 28, 17, 42, 6, 166384),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'request_depth_max': 3,
 'response_received_count': 5,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'start_time': datetime.datetime(2020, 5, 28, 17, 41, 57, 519181)}
2020-05-28 20:42:06 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-28 20:42:26 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: soccerscraper)
2020-05-28 20:42:26 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-28 20:42:26 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer_test.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-28 20:42:26 [scrapy.extensions.telnet] INFO: Telnet Password: 27ace899d211ed23
2020-05-28 20:42:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-28 20:42:26 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-28 20:42:26 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-28 20:42:26 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-28 20:42:26 [scrapy.core.engine] INFO: Spider opened
2020-05-28 20:42:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-28 20:42:26 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2020-05-28 20:42:36 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000143FF672A48>>
Traceback (most recent call last):
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\defer.py", line 161, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\extensions\feedexport.py", line 260, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\exporters.py", line 129, in export_item
    data = self.encoder.encode(itemdict)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\serialize.py", line 36, in default
    return super(ScrapyJSONEncoder, self).default(o)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type Selector is not JSON serializable
2020-05-28 20:42:36 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-28 20:42:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2441,
 'downloader/request_count': 5,
 'downloader/request_method_count/GET': 5,
 'downloader/response_bytes': 52940,
 'downloader/response_count': 5,
 'downloader/response_status_count/200': 5,
 'elapsed_time_seconds': 9.272384,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 28, 17, 42, 36, 140876),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'request_depth_max': 3,
 'response_received_count': 5,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'start_time': datetime.datetime(2020, 5, 28, 17, 42, 26, 868492)}
2020-05-28 20:42:36 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-28 20:42:54 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: soccerscraper)
2020-05-28 20:42:54 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-28 20:42:54 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer_test.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-28 20:42:54 [scrapy.extensions.telnet] INFO: Telnet Password: 0b20531ae362dbe2
2020-05-28 20:42:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-28 20:42:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-28 20:42:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-28 20:42:55 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-28 20:42:55 [scrapy.core.engine] INFO: Spider opened
2020-05-28 20:42:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-28 20:42:55 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2020-05-28 20:43:00 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x000002014DA77F88>>
Traceback (most recent call last):
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\defer.py", line 161, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\extensions\feedexport.py", line 260, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\exporters.py", line 129, in export_item
    data = self.encoder.encode(itemdict)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\serialize.py", line 36, in default
    return super(ScrapyJSONEncoder, self).default(o)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type Selector is not JSON serializable
2020-05-28 20:43:00 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-28 20:43:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2441,
 'downloader/request_count': 5,
 'downloader/request_method_count/GET': 5,
 'downloader/response_bytes': 52917,
 'downloader/response_count': 5,
 'downloader/response_status_count/200': 5,
 'elapsed_time_seconds': 5.255533,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 28, 17, 43, 0, 706628),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'request_depth_max': 3,
 'response_received_count': 5,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'start_time': datetime.datetime(2020, 5, 28, 17, 42, 55, 451095)}
2020-05-28 20:43:00 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-28 20:43:51 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: soccerscraper)
2020-05-28 20:43:51 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-28 20:43:51 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer_test.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-28 20:43:51 [scrapy.extensions.telnet] INFO: Telnet Password: 065aa987f77346bd
2020-05-28 20:43:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-28 20:43:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-28 20:43:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-28 20:43:51 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-28 20:43:51 [scrapy.core.engine] INFO: Spider opened
2020-05-28 20:43:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-28 20:43:51 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2020-05-28 20:43:56 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x000001E181FA14C8>>
Traceback (most recent call last):
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\defer.py", line 161, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\extensions\feedexport.py", line 260, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\exporters.py", line 129, in export_item
    data = self.encoder.encode(itemdict)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\serialize.py", line 36, in default
    return super(ScrapyJSONEncoder, self).default(o)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type Selector is not JSON serializable
2020-05-28 20:43:56 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-28 20:43:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2441,
 'downloader/request_count': 5,
 'downloader/request_method_count/GET': 5,
 'downloader/response_bytes': 53034,
 'downloader/response_count': 5,
 'downloader/response_status_count/200': 5,
 'elapsed_time_seconds': 5.031531,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 28, 17, 43, 56, 957411),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'request_depth_max': 3,
 'response_received_count': 5,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'start_time': datetime.datetime(2020, 5, 28, 17, 43, 51, 925880)}
2020-05-28 20:43:56 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-28 20:44:24 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: soccerscraper)
2020-05-28 20:44:24 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-28 20:44:24 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer_test.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-28 20:44:24 [scrapy.extensions.telnet] INFO: Telnet Password: f7377b4b52c02a5c
2020-05-28 20:44:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-28 20:44:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-28 20:44:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-28 20:44:25 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-28 20:44:25 [scrapy.core.engine] INFO: Spider opened
2020-05-28 20:44:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-28 20:44:25 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2020-05-28 20:44:34 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x000001909198F408>>
Traceback (most recent call last):
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\defer.py", line 161, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\extensions\feedexport.py", line 260, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\exporters.py", line 129, in export_item
    data = self.encoder.encode(itemdict)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\serialize.py", line 36, in default
    return super(ScrapyJSONEncoder, self).default(o)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type Selector is not JSON serializable
2020-05-28 20:44:34 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-28 20:44:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2441,
 'downloader/request_count': 5,
 'downloader/request_method_count/GET': 5,
 'downloader/response_bytes': 52824,
 'downloader/response_count': 5,
 'downloader/response_status_count/200': 5,
 'elapsed_time_seconds': 8.809421,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 28, 17, 44, 34, 276202),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'request_depth_max': 3,
 'response_received_count': 5,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'start_time': datetime.datetime(2020, 5, 28, 17, 44, 25, 466781)}
2020-05-28 20:44:34 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-28 20:45:00 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: soccerscraper)
2020-05-28 20:45:00 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-28 20:45:00 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer_test.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-28 20:45:00 [scrapy.extensions.telnet] INFO: Telnet Password: 6cf298a4b787253b
2020-05-28 20:45:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-28 20:45:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-28 20:45:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-28 20:45:01 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-28 20:45:01 [scrapy.core.engine] INFO: Spider opened
2020-05-28 20:45:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-28 20:45:01 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2020-05-28 20:45:06 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000234CE6C2A88>>
Traceback (most recent call last):
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\defer.py", line 161, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\extensions\feedexport.py", line 260, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\exporters.py", line 129, in export_item
    data = self.encoder.encode(itemdict)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\site-packages\scrapy\utils\serialize.py", line 36, in default
    return super(ScrapyJSONEncoder, self).default(o)
  File "C:\Users\Alex\Anaconda3\envs\neo4j_env\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type Selector is not JSON serializable
2020-05-28 20:45:06 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-28 20:45:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2441,
 'downloader/request_count': 5,
 'downloader/request_method_count/GET': 5,
 'downloader/response_bytes': 53007,
 'downloader/response_count': 5,
 'downloader/response_status_count/200': 5,
 'elapsed_time_seconds': 4.935521,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 28, 17, 45, 6, 41268),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'request_depth_max': 3,
 'response_received_count': 5,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'start_time': datetime.datetime(2020, 5, 28, 17, 45, 1, 105747)}
2020-05-28 20:45:06 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-28 20:46:11 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: soccerscraper)
2020-05-28 20:46:11 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-28 20:46:11 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer_test.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-28 20:46:11 [scrapy.extensions.telnet] INFO: Telnet Password: d027bb827db76eca
2020-05-28 20:46:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-28 20:46:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-28 20:46:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-28 20:46:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-28 20:46:12 [scrapy.core.engine] INFO: Spider opened
2020-05-28 20:46:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-28 20:46:12 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2020-05-28 20:46:18 [scrapy.core.engine] INFO: Closing spider (finished)
2020-05-28 20:46:18 [scrapy.extensions.feedexport] INFO: Stored json feed (1 items) in: soccer_test.json
2020-05-28 20:46:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2441,
 'downloader/request_count': 5,
 'downloader/request_method_count/GET': 5,
 'downloader/response_bytes': 53190,
 'downloader/response_count': 5,
 'downloader/response_status_count/200': 5,
 'elapsed_time_seconds': 6.151432,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 28, 17, 46, 18, 322592),
 'item_scraped_count': 1,
 'log_count/INFO': 11,
 'request_depth_max': 3,
 'response_received_count': 5,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'start_time': datetime.datetime(2020, 5, 28, 17, 46, 12, 171160)}
2020-05-28 20:46:18 [scrapy.core.engine] INFO: Spider closed (finished)
2020-05-28 20:47:55 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: soccerscraper)
2020-05-28 20:47:55 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-05-28 20:47:55 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'soccerscraper',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'FEED_FORMAT': 'json',
 'FEED_URI': 'soccer_greece_div1.json',
 'LOG_FILE': 'soccer.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'soccerscraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['soccerscraper.spiders']}
2020-05-28 20:47:55 [scrapy.extensions.telnet] INFO: Telnet Password: 33f4048be8c8eb77
2020-05-28 20:47:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-05-28 20:47:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-28 20:47:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-28 20:47:55 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-05-28 20:47:55 [scrapy.core.engine] INFO: Spider opened
2020-05-28 20:47:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-28 20:47:55 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
